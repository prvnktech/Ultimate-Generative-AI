{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35106a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "LATENT_DIM = 512\n",
    "IMG_CHANNELS = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44d420cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def mapping_network(latent_dim, layers=8):\n",
    "    model = tf.keras.Sequential(name=\"mapping_network\")\n",
    "    for _ in range(layers):\n",
    "        model.add(tf.keras.layers.Dense(latent_dim, activation=\"relu\"))\n",
    "    return model\n",
    "\n",
    "mapping_net = mapping_network(LATENT_DIM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86711e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaIN(tf.keras.layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        content, style = inputs\n",
    "        mean, variance = tf.nn.moments(content, axes=[1, 2], keepdims=True)\n",
    "        normalized = (content - mean) / tf.sqrt(variance + 1e-8)\n",
    "        scale, bias = style\n",
    "        return scale * normalized + bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7b4532f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def progressive_block(input_shape):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = tf.keras.layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\")(inputs)\n",
    "    x = tf.keras.layers.UpSampling2D()(x)\n",
    "    x = tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    return tf.keras.Model(inputs, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2de9339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 512)]             0         \n",
      "                                                                 \n",
      " mapping_network (Sequentia  (None, 512)               2101248   \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 2048)              1050624   \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " model (Functional)          (None, 8, 8, 64)          221376    \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 8, 3)           195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3373443 (12.87 MB)\n",
      "Trainable params: 3373443 (12.87 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_generator():\n",
    "    z = tf.keras.Input(shape=(LATENT_DIM,))\n",
    "    mapping = mapping_network(LATENT_DIM)\n",
    "    w = mapping(z)\n",
    "\n",
    "    x = tf.keras.layers.Dense(4 * 4 * 128)(w)\n",
    "    x = tf.keras.layers.Reshape((4, 4, 128))(x)\n",
    "\n",
    "    block = progressive_block((4, 4, 128))\n",
    "    x = block(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        IMG_CHANNELS, kernel_size=1, activation=\"tanh\"\n",
    "    )(x)\n",
    "\n",
    "    return tf.keras.Model(z, x, name=\"generator\")\n",
    "\n",
    "generator = build_generator()\n",
    "generator.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6517819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 8, 8, 3)]         0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 8, 8, 64)          1792      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5889 (23.00 KB)\n",
      "Trainable params: 5889 (23.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_discriminator():\n",
    "    inputs = tf.keras.Input(shape=(8, 8, IMG_CHANNELS))\n",
    "    x = tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\")(inputs)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(1)(x)\n",
    "    return tf.keras.Model(inputs, x, name=\"discriminator\")\n",
    "\n",
    "discriminator = build_discriminator()\n",
    "discriminator.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5ad99a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_images(images, rows, cols):\n",
    "    images = (images + 1) / 2\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(8, 8))\n",
    "    for i, ax in enumerate(axs.flatten()):\n",
    "        ax.imshow(images[i])\n",
    "        ax.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a499acdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "noise = tf.random.normal([9, LATENT_DIM])\n",
    "fake_images = generator(noise)\n",
    "visualize_images(fake_images.numpy(), 3, 3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
