{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba04a2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "LATENT_DIM = 512\n",
    "BATCH_SIZE = 16\n",
    "IMAGE_SIZE = 32\n",
    "EPOCHS = 5\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cda413e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_network(latent_dim, layers=8):\n",
    "    layers_list = []\n",
    "    for _ in range(layers):\n",
    "        layers_list.append(nn.Linear(latent_dim, latent_dim))\n",
    "        layers_list.append(nn.ReLU())\n",
    "    return nn.Sequential(*layers_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a18af672",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaIN(nn.Module):\n",
    "    def forward(self, content, style):\n",
    "        mean = content.mean([2, 3], keepdim=True)\n",
    "        std = content.std([2, 3], keepdim=True)\n",
    "        normalized = (content - mean) / (std + 1e-8)\n",
    "        scale, bias = style\n",
    "        return scale * normalized + bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "638c8c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressiveBlock(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_c, out_c, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(out_c, out_c, 3, padding=1)\n",
    "        self.upsample = nn.Upsample(scale_factor=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.upsample(x)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ece8017",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mapping = mapping_network(LATENT_DIM)\n",
    "        self.fc = nn.Linear(LATENT_DIM, 128 * 4 * 4)\n",
    "        self.block1 = ProgressiveBlock(128, 128)\n",
    "        self.block2 = ProgressiveBlock(128, 64)\n",
    "        self.block3 = ProgressiveBlock(64, 32)\n",
    "        self.to_rgb = nn.Conv2d(32, 3, 1)\n",
    "\n",
    "    def forward(self, z):\n",
    "        w = self.mapping(z)\n",
    "        x = self.fc(w).view(-1, 128, 4, 4)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        return torch.sigmoid(self.to_rgb(x))\n",
    "\n",
    "G = Generator().to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef77bbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((4, 4))\n",
    "        )\n",
    "        self.classifier = nn.Linear(128 * 4 * 4, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.classifier(x)\n",
    "\n",
    "D = Discriminator().to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a21aa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "g_opt = optim.Adam(G.parameters(), lr=1e-4)\n",
    "d_opt = optim.Adam(D.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e0ea475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: G=0.8892, D=1.0970\n",
      "Epoch 2: G=1.1392, D=0.8143\n",
      "Epoch 3: G=3.2827, D=0.0613\n",
      "Epoch 4: G=4.5017, D=0.0176\n",
      "Epoch 5: G=5.1645, D=0.0089\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    for _ in range(50):\n",
    "        real = torch.rand(BATCH_SIZE, 3, IMAGE_SIZE, IMAGE_SIZE).to(DEVICE)\n",
    "        z = torch.randn(BATCH_SIZE, LATENT_DIM).to(DEVICE)\n",
    "\n",
    "        fake = G(z)\n",
    "\n",
    "        d_loss = criterion(D(real), torch.ones(BATCH_SIZE, 1).to(DEVICE)) + \\\n",
    "                 criterion(D(fake.detach()), torch.zeros(BATCH_SIZE, 1).to(DEVICE))\n",
    "\n",
    "        d_opt.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_opt.step()\n",
    "\n",
    "        g_loss = criterion(D(fake), torch.ones(BATCH_SIZE, 1).to(DEVICE))\n",
    "        g_opt.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_opt.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: G={g_loss.item():.4f}, D={d_loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fe01976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_images(images, rows, cols):\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(6, 6))\n",
    "    for i, ax in enumerate(axs.flatten()):\n",
    "        img = images[i].detach().cpu().permute(1, 2, 0).numpy()\n",
    "        ax.imshow(img)\n",
    "        ax.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "z = torch.randn(9, LATENT_DIM).to(DEVICE)\n",
    "show_images(G(z), 3, 3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
